# AI Vision Monitoring System

ğŸ”´ **Real-time AI-powered video and audio monitoring with anomaly detection**

A comprehensive security monitoring solution featuring:
- ğŸ¥ Live video feed with SAM 3 object segmentation
- ğŸ¤ Real-time audio analysis and classification
- ğŸ¯ Motion-based anomaly detection
- ğŸš¨ Multi-channel alerting (Email, SMS, Desktop)
- âœ¨ AI-powered scene summarization

![Python](https://img.shields.io/badge/Python-3.9+-blue.svg)
![Streamlit](https://img.shields.io/badge/Streamlit-1.38+-red.svg)
![License](https://img.shields.io/badge/License-MIT-green.svg)

## ğŸ“‹ Table of Contents

- [Features](#-features)
- [Quick Start](#-quick-start)
- [Installation](#-installation)
- [Usage](#-usage)
- [Configuration](#-configuration)
- [Architecture](#-architecture)
- [API Reference](#-api-reference)
- [Docker](#-docker)
- [Development](#-development)
- [Testing](#-testing)

## ğŸ¯ Features

### Video Processing
- **Live webcam capture** at configurable FPS (up to 4K @ 30FPS)
- **SAM 3 integration** for real-time object segmentation
- **Low-light enhancement** using CLAHE
- **Multi-camera support** via configuration
- **Auto-reconnect** on camera disconnect

### Audio Processing
- **Real-time microphone capture** with PyAudio
- **Feature extraction**: MFCC, Spectral Centroid, Zero Crossing Rate
- **Sound event classification** (Scream, Glass Break, Gunshot, etc.)
- **Voice Activity Detection** (WebRTC VAD)
- **Noise suppression**

### Anomaly Detection
```python
# Anomaly score formula
anomaly_score = motion_magnitude * (1 - iou_prev_mask) * object_count_change
```

| Trigger | Threshold |
|---------|-----------|
| High Anomaly | >0.75 |
| Audio Event | >0.85 |
| Person Detected | True |

### Alert System
- ğŸ”” **Desktop notifications** - Immediate
- ğŸ“§ **Email alerts** - HTML reports with clips
- ğŸ“± **SMS alerts** - Twilio integration
- ğŸ“Š **Event logging** - Structured JSON logs

### Web UI (Streamlit)
- Live video feed with mask overlay
- Audio waveform visualization
- Anomaly score gauge (0-100)
- Interactive event timeline
- Alert history table
- Dashboard metrics

## ğŸš€ Quick Start

```bash
# Clone the repository
git clone https://github.com/irfan0807/visonSystem.git
cd visonSystem/monitoring_app

# Run setup script
chmod +x setup.sh
./setup.sh

# Launch the application
streamlit run app.py --server.port 8501
```

Open your browser at http://localhost:8501

## ğŸ“¦ Installation

### Prerequisites

- Python 3.9+
- pip
- (Optional) NVIDIA GPU with CUDA for SAM acceleration

### Manual Installation

```bash
# Create virtual environment
python3 -m venv venv
source venv/bin/activate  # Linux/Mac
# or: venv\Scripts\activate  # Windows

# Install dependencies
pip install -r requirements.txt

# Create directories
mkdir -p data/{events,clips,logs} models

# Train audio model (optional)
python audio_train.py --synthetic

# Run the app
streamlit run app.py
```

### System Dependencies (Linux)

```bash
# For PyAudio
sudo apt-get install portaudio19-dev

# For OpenCV
sudo apt-get install libgl1-mesa-glx libglib2.0-0
```

## ğŸ® Usage

### Demo Mode

The application starts in demo mode by default, showing simulated data:

```bash
streamlit run app.py
```

### Live Monitoring

1. Connect a webcam
2. Disable "Demo Mode" in the sidebar
3. Click "Start" to begin monitoring

### Command Line Options

```bash
# Custom port
streamlit run app.py --server.port 8080

# Enable debug mode
streamlit run app.py -- --debug

# Headless mode
streamlit run app.py --server.headless true
```

### Training Custom Audio Model

```bash
# Using synthetic data
python audio_train.py --synthetic --samples-per-class 100

# Using custom dataset
python audio_train.py --data-dir /path/to/audio/dataset

# Dataset structure:
# data/audio/
#   â”œâ”€â”€ normal/
#   â”‚   â”œâ”€â”€ sample1.wav
#   â”‚   â””â”€â”€ ...
#   â”œâ”€â”€ scream/
#   â”œâ”€â”€ glass_break/
#   â””â”€â”€ ...
```

## âš™ï¸ Configuration

Configuration is managed via `config.yaml`:

```yaml
# Main settings
app_name: "AI Vision Monitor"
debug: false
demo_mode: true

# Performance
target_fps: 30
max_latency_ms: 150
max_memory_gb: 4.0

# Camera settings
cameras:
  - id: 0
    name: "Main Camera"
    source: "0"  # Device ID or RTSP URL
    width: 1280
    height: 720
    fps: 30

# Audio settings
audio:
  sample_rate: 16000
  vad_mode: 2
  noise_suppression: true

# Anomaly detection thresholds
anomaly:
  motion_threshold: 0.3
  anomaly_threshold: 0.75
  scream_threshold: 0.85
  glass_break_threshold: 0.80

# AI settings
ai:
  openai_model: "gpt-4o-mini"
  scene_summary_interval: 30
  sam_model_type: "vit_b"
  use_gpu: true

# Alerts
alerts:
  email_enabled: false
  sms_enabled: false
  desktop_enabled: true
```

### Environment Variables

Sensitive configuration via environment variables:

```bash
export OPENAI_API_KEY="your-api-key"
export TWILIO_SID="your-twilio-sid"
export TWILIO_TOKEN="your-twilio-token"
export SMTP_PASSWORD="your-email-password"
```

## ğŸ—ï¸ Architecture

```
monitoring_app/
â”œâ”€â”€ app.py                    # Main Streamlit application
â”œâ”€â”€ core/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ video_processor.py    # SAM 3 video segmentation
â”‚   â”œâ”€â”€ audio_processor.py    # Real-time audio analysis
â”‚   â””â”€â”€ anomaly_detector.py   # Motion + segmentation anomaly scoring
â”œâ”€â”€ models/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ audio_classifier.pkl  # Pre-trained audio model
â”‚   â””â”€â”€ scene_descriptions.py # AI-powered scene summaries
â”œâ”€â”€ utils/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ alerts.py             # Email/SMS/Desktop notifications
â”‚   â”œâ”€â”€ logger.py             # Structured logging
â”‚   â””â”€â”€ config.py             # YAML configuration
â”œâ”€â”€ static/                   # CSS/JS for UI
â”œâ”€â”€ data/                     # Runtime data
â”‚   â”œâ”€â”€ events/
â”‚   â”œâ”€â”€ clips/
â”‚   â””â”€â”€ logs/
â”œâ”€â”€ tests/                    # Unit tests
â”œâ”€â”€ requirements.txt
â”œâ”€â”€ audio_train.py            # Audio model training
â”œâ”€â”€ setup.sh                  # Setup script
â”œâ”€â”€ Dockerfile
â”œâ”€â”€ docker-compose.yml
â””â”€â”€ config.yaml
```

## ğŸ“š API Reference

### VideoProcessor

```python
from core import VideoProcessor

processor = VideoProcessor(
    target_fps=30,
    enable_sam=True,
    enable_anomaly_detection=True
)

# Start capture
processor.start()

# Get current frame
frame = processor.get_frame()

# Get processing result
result = processor.get_result()
# result.frame, result.detections, result.anomaly_score

# Stop capture
processor.stop()
```

### AudioProcessor

```python
from core import AudioProcessor

processor = AudioProcessor(
    sample_rate=16000,
    noise_suppression=True
)

processor.start()

# Get classification
classification = processor.get_classification()
# classification.label, classification.confidence

# Get waveform for visualization
waveform = processor.get_waveform(duration=2.0)

processor.stop()
```

### AlertManager

```python
from utils import AlertManager

manager = AlertManager(
    email_enabled=True,
    desktop_enabled=True
)

manager.start()

# Trigger alert
manager.trigger_alert(
    alert_type="anomaly",
    message="Motion detected",
    severity="high",
    data={'score': 0.85}
)

# Get history
alerts = manager.get_history(limit=10)

manager.stop()
```

## ğŸ³ Docker

### Using Docker Compose

```bash
# Build and run
docker-compose up -d

# With environment variables
OPENAI_API_KEY=your-key docker-compose up -d

# Development mode
docker-compose --profile dev up
```

### Using Dockerfile

```bash
# Build
docker build -t ai-vision-monitor .

# Run
docker run -p 8501:8501 \
  -e OPENAI_API_KEY=your-key \
  -v $(pwd)/data:/app/data \
  ai-vision-monitor
```

## ğŸ”§ Development

### Setup Development Environment

```bash
# Install dev dependencies
pip install -r requirements.txt

# Install pre-commit hooks
pre-commit install

# Run linting
flake8 .
black --check .
mypy .
```

### Code Style

- Follow PEP 8
- Use type hints
- Document with docstrings
- Maximum line length: 100 characters

## ğŸ§ª Testing

```bash
# Run all tests
pytest

# Run with coverage
pytest --cov=. --cov-report=html

# Run specific test file
pytest tests/test_anomaly_detector.py -v

# Run with verbose output
pytest -v --tb=short
```

### Test Coverage Target: 80%+

## ğŸ“Š Performance Targets

| Metric | Target |
|--------|--------|
| End-to-End Latency | <150ms |
| SAM 3 FPS | >15 FPS (RTX 3060) |
| Memory Usage | <4GB |
| CPU Usage | <30% (with GPU) |

## ğŸ”’ Edge Cases Handled

âœ… **Low light** â†’ Auto-exposure + CLAHE enhancement  
âœ… **Background noise** â†’ VAD + noise gating  
âœ… **Camera disconnect** â†’ Auto-reconnect with retry  
âœ… **High CPU** â†’ Frame skipping + priority queue  
âœ… **Network issues** â†’ Offline mode + queued alerts  

## ğŸ“„ License

MIT License - see [LICENSE](LICENSE) for details.

## ğŸ¤ Contributing

1. Fork the repository
2. Create a feature branch
3. Make your changes
4. Run tests
5. Submit a pull request

## ğŸ“ Support

- ğŸ“§ Email: support@example.com
- ğŸ› Issues: [GitHub Issues](https://github.com/irfan0807/visonSystem/issues)
- ğŸ“– Docs: [Wiki](https://github.com/irfan0807/visonSystem/wiki)